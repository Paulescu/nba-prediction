{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f7bb5d-6222-4478-a231-09c27102a556",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    " - Covert game date to month only\n",
    " - Compile rolling means and current win streak for each team as home team and as visitor team \n",
    " - Process data in sequential format for each team regardless whether home or away (necessary 1st step for following procedures.)\n",
    " - Compile sequential data into head-to-head matchup data for each team pair \n",
    " - Compile sequential data into rolling means and current win streak for each team regardless of home or away a\n",
    " - Merge sequential data features back into main dataframe\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a6e6b9-f500-4465-9427-f6c16d96a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.common_functions import plot_corr_barchart, plot_corr_vs_target, run_sweetviz_report\n",
    "\n",
    "from pathlib import Path  #for Windows/Linux compatibility\n",
    "DATAPATH = Path(r'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8765810b-aa24-4901-a2aa-2d2d57a7b921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>VISITOR_TEAM_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "      <th>PLAYOFF</th>\n",
       "      <th>CONFERENCE_x</th>\n",
       "      <th>G_x</th>\n",
       "      <th>W_x</th>\n",
       "      <th>L_x</th>\n",
       "      <th>W_PCT_x</th>\n",
       "      <th>HOME_W_x</th>\n",
       "      <th>HOME_L_x</th>\n",
       "      <th>HOME_W_PCT_x</th>\n",
       "      <th>ROAD_W_x</th>\n",
       "      <th>ROAD_L_x</th>\n",
       "      <th>ROAD_W_PCT_x</th>\n",
       "      <th>CONFERENCE_y</th>\n",
       "      <th>G_y</th>\n",
       "      <th>W_y</th>\n",
       "      <th>L_y</th>\n",
       "      <th>W_PCT_y</th>\n",
       "      <th>HOME_W_y</th>\n",
       "      <th>HOME_L_y</th>\n",
       "      <th>HOME_W_PCT_y</th>\n",
       "      <th>ROAD_W_y</th>\n",
       "      <th>ROAD_L_y</th>\n",
       "      <th>ROAD_W_PCT_y</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>41500124</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>2015</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.379</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>0.585</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>0.585</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>41500123</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>2015</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.278</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.318</td>\n",
       "      <td>13.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>0.585</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>0.585</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-28</td>\n",
       "      <td>41300114</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>2013</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.280</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.375</td>\n",
       "      <td>25.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>0.524</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>0.659</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-26</td>\n",
       "      <td>41300113</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>2013</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.389</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.500</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>0.524</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>0.659</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-26</td>\n",
       "      <td>40900114</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>2009</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.263</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.394</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>0.720</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23042</th>\n",
       "      <td>2003-11-22</td>\n",
       "      <td>20300177</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>2003</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.200</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.571</td>\n",
       "      <td>21.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.357</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.286</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23043</th>\n",
       "      <td>2003-11-17</td>\n",
       "      <td>20300141</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>2003</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.231</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.375</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23044</th>\n",
       "      <td>2003-11-15</td>\n",
       "      <td>20300128</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>1610612751</td>\n",
       "      <td>2003</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.444</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23045</th>\n",
       "      <td>2003-11-03</td>\n",
       "      <td>20300042</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>2003</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.222</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23046</th>\n",
       "      <td>2003-11-01</td>\n",
       "      <td>20300029</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>1610612754</td>\n",
       "      <td>2003</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.375</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.286</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23047 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GAME_DATE_EST   GAME_ID  HOME_TEAM_ID  VISITOR_TEAM_ID  SEASON  \\\n",
       "0        2016-04-25  41500124    1610612766       1610612748    2015   \n",
       "1        2016-04-23  41500123    1610612766       1610612748    2015   \n",
       "2        2014-04-28  41300114    1610612766       1610612748    2013   \n",
       "3        2014-04-26  41300113    1610612766       1610612748    2013   \n",
       "4        2010-04-26  40900114    1610612766       1610612753    2009   \n",
       "...             ...       ...           ...              ...     ...   \n",
       "23042    2003-11-22  20300177    1610612737       1610612739    2003   \n",
       "23043    2003-11-17  20300141    1610612737       1610612764    2003   \n",
       "23044    2003-11-15  20300128    1610612737       1610612751    2003   \n",
       "23045    2003-11-03  20300042    1610612737       1610612740    2003   \n",
       "23046    2003-11-01  20300029    1610612737       1610612754    2003   \n",
       "\n",
       "       PTS_home  FG_PCT_home  FT_PCT_home  FG3_PCT_home  AST_home  REB_home  \\\n",
       "0          89.0        0.400        0.833         0.250      10.0      36.0   \n",
       "1          96.0        0.389        0.955         0.278      18.0      47.0   \n",
       "2          98.0        0.507        0.700         0.280      22.0      36.0   \n",
       "3          85.0        0.415        0.727         0.389      21.0      38.0   \n",
       "4          90.0        0.451        0.636         0.263      27.0      36.0   \n",
       "...         ...          ...          ...           ...       ...       ...   \n",
       "23042      92.0        0.447        0.933         0.200      25.0      45.0   \n",
       "23043      97.0        0.423        0.872         0.231      12.0      39.0   \n",
       "23044      85.0        0.382        0.767         0.333      19.0      39.0   \n",
       "23045      90.0        0.427        0.652         0.333      20.0      50.0   \n",
       "23046      99.0        0.468        0.677         0.375      23.0      36.0   \n",
       "\n",
       "       PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  AST_away  REB_away  \\\n",
       "0          85.0        0.395        0.667         0.379      20.0      46.0   \n",
       "1          80.0        0.342        0.633         0.318      13.0      53.0   \n",
       "2         109.0        0.500        0.759         0.375      25.0      33.0   \n",
       "3          98.0        0.434        0.850         0.500      26.0      39.0   \n",
       "4          99.0        0.418        0.714         0.394      18.0      38.0   \n",
       "...         ...          ...          ...           ...       ...       ...   \n",
       "23042      83.0        0.330        0.840         0.571      21.0      54.0   \n",
       "23043     106.0        0.390        0.750         0.375      19.0      44.0   \n",
       "23044     100.0        0.479        0.867         0.444      23.0      38.0   \n",
       "23045      80.0        0.407        0.588         0.222      21.0      42.0   \n",
       "23046     103.0        0.448        0.568         0.286      19.0      52.0   \n",
       "\n",
       "       HOME_TEAM_WINS  PLAYOFF  CONFERENCE_x  G_x  W_x  L_x  W_PCT_x  \\\n",
       "0                   1        1             0   82   48   34    0.585   \n",
       "1                   1        1             0   82   48   34    0.585   \n",
       "2                   0        1             0   82   43   39    0.524   \n",
       "3                   0        1             0   82   43   39    0.524   \n",
       "4                   0        1             0   82   44   38    0.537   \n",
       "...               ...      ...           ...  ...  ...  ...      ...   \n",
       "23042               1        0             0   14    5    9    0.357   \n",
       "23043               0        0             0   11    3    8    0.273   \n",
       "23044               0        0             0   10    3    7    0.300   \n",
       "23045               1        0             0    4    1    3    0.250   \n",
       "23046               0        0             0    3    0    3    0.000   \n",
       "\n",
       "       HOME_W_x  HOME_L_x  HOME_W_PCT_x  ROAD_W_x  ROAD_L_x  ROAD_W_PCT_x  \\\n",
       "0            30        11      0.731707        18        23      0.439024   \n",
       "1            30        11      0.731707        18        23      0.439024   \n",
       "2            25        16      0.609756        18        23      0.439024   \n",
       "3            25        16      0.609756        18        23      0.439024   \n",
       "4            31        10      0.756098        13        28      0.317073   \n",
       "...         ...       ...           ...       ...       ...           ...   \n",
       "23042         2         3      0.400000         3         6      0.333333   \n",
       "23043         1         3      0.250000         2         5      0.285714   \n",
       "23044         1         2      0.333333         2         5      0.285714   \n",
       "23045         1         1      0.500000         0         2      0.000000   \n",
       "23046         0         1      0.000000         0         2      0.000000   \n",
       "\n",
       "       CONFERENCE_y  G_y  W_y  L_y  W_PCT_y  HOME_W_y  HOME_L_y  HOME_W_PCT_y  \\\n",
       "0                 0   82   48   34    0.585        28        13      0.682927   \n",
       "1                 0   82   48   34    0.585        28        13      0.682927   \n",
       "2                 0   82   54   28    0.659        32         9      0.780488   \n",
       "3                 0   82   54   28    0.659        32         9      0.780488   \n",
       "4                 0   82   59   23    0.720        34         7      0.829268   \n",
       "...             ...  ...  ...  ...      ...       ...       ...           ...   \n",
       "23042             0   14    4   10    0.286         4         2      0.666667   \n",
       "23043             0   10    4    6    0.400         2         3      0.400000   \n",
       "23044             0   10    5    5    0.500         2         3      0.400000   \n",
       "23045             0    4    3    1    0.750         2         0      1.000000   \n",
       "23046             0    3    2    1    0.667         0         1      0.000000   \n",
       "\n",
       "       ROAD_W_y  ROAD_L_y  ROAD_W_PCT_y  TARGET  \n",
       "0            20        21      0.487805     0.0  \n",
       "1            20        21      0.487805     1.0  \n",
       "2            22        19      0.536585     1.0  \n",
       "3            22        19      0.536585     0.0  \n",
       "4            25        16      0.609756     0.0  \n",
       "...         ...       ...           ...     ...  \n",
       "23042         0         8      0.000000     0.0  \n",
       "23043         2         3      0.400000     1.0  \n",
       "23044         3         2      0.600000     0.0  \n",
       "23045         1         1      0.500000     0.0  \n",
       "23046         2         0      1.000000     1.0  \n",
       "\n",
       "[23047 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(DATAPATH / \"train.csv\")\n",
    "test = pd.read_csv(DATAPATH / \"test.csv\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de2db65-2803-45c0-831f-23423c610078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datatypes(df):\n",
    "    df['GAME_DATE_EST'] = pd.to_datetime(df['GAME_DATE_EST'])\n",
    "\n",
    "    long_integer_fields = ['GAME_ID', 'HOME_TEAM_ID', 'VISITOR_TEAM_ID', 'SEASON']\n",
    "\n",
    "    #convert long integer fields to int32 from int64\n",
    "    for field in long_integer_fields:\n",
    "        df[field] = df[field].astype('int32')\n",
    "    \n",
    "    #convert the remaining int64s to int8\n",
    "    for field in df.select_dtypes(include=['int64']).columns.tolist():\n",
    "        df[field] = df[field].astype('int8')\n",
    "        \n",
    "    #convert float64s to float16s\n",
    "    for field in df.select_dtypes(include=['float64']).columns.tolist():\n",
    "        df[field] = df[field].astype('float16')\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7964066-6860-46a1-8383-ca0edbf4b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    #convert game date to month to limit cardinality\n",
    "\n",
    "    df['MONTH'] = df['GAME_DATE_EST'].dt.month\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3640ba5-1f7a-4c51-bed8-dd58054d60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_playoff_games(df):\n",
    "    \n",
    "    df = df[df[\"PLAYOFF\"] == 0]\n",
    "    \n",
    "    df = df.drop(\"PLAYOFF\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93968e69-9d28-41c0-967d-e24614b71269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_home_visitor(df, location, roll_list): \n",
    "    \n",
    "    # location = \"HOME\" or \"VISITOR\"\n",
    "    # roll_list = list of number of games for each rolling mean, e.g. [3, 5, 7, 10, 15]\n",
    "\n",
    "    # new version 2022-10-31\n",
    "    # now ignoring season boundaries and with longer rolling means \n",
    "    # AND create a field where the all-team average is subtracted from each field\n",
    "    \n",
    "    \n",
    "    # add features showing how well the home team has done in its last home games \n",
    "    # and how well the visitor team has done in its last away games\n",
    "    # add rolling means \n",
    "    # add win streaks (negative number if losing streak)\n",
    "    # these are for the home teams last  *home* games\n",
    "    # and for the visitor teams last *away* games\n",
    "    \n",
    "    location_id = location + \"_TEAM_ID\"\n",
    "\n",
    "    # sort games by the order in which they were played for each home or visitor team\n",
    "    df = df.sort_values(by = [location_id, 'GAME_DATE_EST'], axis=0, ascending=[True, True,], ignore_index=True)\n",
    "    \n",
    "    # Win streak, negative if a losing streak\n",
    "    df[location + '_TEAM_WIN_STREAK'] = df['HOME_TEAM_WINS'].groupby((df['HOME_TEAM_WINS'] != df.groupby([location_id])['HOME_TEAM_WINS'].shift()).cumsum()).cumcount() + 1\n",
    "    df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  = df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  * -1\n",
    "\n",
    "    # If visitor, the streak has opposite meaning (3 wins for home team is 3 losses in a row for visitor)\n",
    "    if location == 'VISITOR':\n",
    "        df[location + '_TEAM_WIN_STREAK'] = - df[location + '_TEAM_WIN_STREAK']  \n",
    "\n",
    "\n",
    "    # rolling means\n",
    "    feature_list = ['HOME_TEAM_WINS', 'PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home']\n",
    "    \n",
    "    if location == 'VISITOR':\n",
    "        feature_list = ['HOME_TEAM_WINS', 'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away']\n",
    "    \n",
    "      \n",
    "    roll_feature_list = []\n",
    "    for feature in feature_list:\n",
    "        for roll in roll_list:\n",
    "            roll_feature_name = location + '_' + feature + '_AVG_LAST_' + str(roll) + '_' + location\n",
    "            if feature == 'HOME_TEAM_WINS': #remove the \"HOME_\" for better readability\n",
    "                roll_feature_name = location + '_' + feature[5:] + '_AVG_LAST_' + str(roll) + '_' + location\n",
    "            roll_feature_list.append(roll_feature_name)\n",
    "            df[roll_feature_name] = df.groupby(['HOME_TEAM_ID'])[feature].rolling(roll).mean().values\n",
    "            \n",
    "    \n",
    "    \n",
    "    # determine league avg for each stat and then subtract it from the each team's avg\n",
    "    # as a measure of how well that team compares to all teams in that moment in time\n",
    "    \n",
    "    #remove win averages from roll list - the league average will always be 0.5 (half the teams win, half lose)\n",
    "    roll_feature_list = [x for x in roll_feature_list if not x.startswith('HOME_TEAM_WINS')]\n",
    "    \n",
    "    df = process_x_minus_league_avg(df, roll_feature_list, location_id)\n",
    "    \n",
    " \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0db99b8-44a7-4269-a610-89785877b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_games_consecutively(df_data):\n",
    "    # re-organize so that all of a team's games can be listed in chronological order whether HOME or VISITOR\n",
    "    # this will facilitate feature engineering (winpct vs team X, 5-game winpct, current win streak, etc...)\n",
    "    \n",
    "    #this data will need to be re-linked back to the main dataframe after all processing is done,\n",
    "    #joining TEAM1 to HOME_TEAM_ID for all records and then TEAM1 to VISITOR_TEAM_ID for all records\n",
    "    \n",
    "    #TEAM1 will be the key field. TEAM2 is used solely to process past team matchups\n",
    "\n",
    "    # all the home games for each team will be selected and then stacked with all the away games\n",
    "    \n",
    "    df_home = pd.DataFrame()\n",
    "    df_home['GAME_DATE_EST'] = df_data['GAME_DATE_EST']\n",
    "    df_home['GAME_ID'] = df_data['GAME_ID']\n",
    "    df_home['TEAM1'] = df_data['HOME_TEAM_ID']\n",
    "    df_home['TEAM1_home'] = 1\n",
    "    df_home['TEAM1_win'] = df_data['HOME_TEAM_WINS']\n",
    "    df_home['TEAM2'] = df_data['VISITOR_TEAM_ID']\n",
    "    df_home['SEASON'] = df_data['SEASON']\n",
    "    \n",
    "    df_home['PTS'] = df_data['PTS_home']\n",
    "    df_home['FG_PCT'] = df_data['FG_PCT_home']\n",
    "    df_home['FT_PCT'] = df_data['FT_PCT_home']\n",
    "    df_home['FG3_PCT'] = df_data['FG3_PCT_home']\n",
    "    df_home['AST'] = df_data['AST_home']\n",
    "    df_home['REB'] = df_data['REB_home']\n",
    "    \n",
    "    # now for visitor teams  \n",
    "\n",
    "    df_visitor = pd.DataFrame()\n",
    "    df_visitor['GAME_DATE_EST'] = df_data['GAME_DATE_EST']\n",
    "    df_visitor['GAME_ID'] = df_data['GAME_ID']\n",
    "    df_visitor['TEAM1'] = df_data['VISITOR_TEAM_ID'] \n",
    "    df_visitor['TEAM1_home'] = 0\n",
    "    df_visitor['TEAM1_win'] = df_data['HOME_TEAM_WINS'].apply(lambda x: 1 if x == 0 else 0)\n",
    "    df_visitor['TEAM2'] = df_data['HOME_TEAM_ID']\n",
    "    df_visitor['SEASON'] = df_data['SEASON']\n",
    "    \n",
    "    df_visitor['PTS'] = df_data['PTS_away']\n",
    "    df_visitor['FG_PCT'] = df_data['FG_PCT_away']\n",
    "    df_visitor['FT_PCT'] = df_data['FT_PCT_away']\n",
    "    df_visitor['FG3_PCT'] = df_data['FG3_PCT_away']\n",
    "    df_visitor['AST'] = df_data['AST_away']\n",
    "    df_visitor['REB'] = df_data['REB_away']\n",
    "\n",
    "    # merge dfs\n",
    "\n",
    "    df = pd.concat([df_home, df_visitor])\n",
    "\n",
    "    column2 = df.pop('TEAM1')\n",
    "    column3 = df.pop('TEAM1_home')\n",
    "    column4 = df.pop('TEAM2')\n",
    "    column5 = df.pop('TEAM1_win')\n",
    "\n",
    "    df.insert(2,'TEAM1', column2)\n",
    "    df.insert(3,'TEAM1_home', column3)\n",
    "    df.insert(4,'TEAM2', column4)\n",
    "    df.insert(5,'TEAM1_win', column5)\n",
    "\n",
    "    df = df.sort_values(by = ['TEAM1', 'GAME_ID'], axis=0, ascending=[True, True], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eaf486e-e99f-4bbd-b7f4-95fe3a5bf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matchups(df, roll_list):\n",
    "\n",
    "    # new version 2022-11-06\n",
    "    # now ignoring season boundaries and added roll parameters\n",
    "\n",
    "    # group all the games that 2 teams played each other \n",
    "    # calculate home team win pct and the home team win/lose streak\n",
    "    \n",
    "\n",
    "    df = df.sort_values(by = ['TEAM1', 'TEAM2','GAME_DATE_EST'], axis=0, ascending=[True, True, True], ignore_index=True)\n",
    "\n",
    "    for roll in roll_list:\n",
    "        df['MATCHUP_WINPCT_' + str(roll)] = df.groupby(['TEAM1','TEAM2'])['TEAM1_win'].rolling(roll).mean().values\n",
    "\n",
    "    df['MATCHUP_WIN_STREAK'] = df['TEAM1_win'].groupby((df['TEAM1_win'] != df.groupby(['TEAM1','TEAM2'])['TEAM1_win'].shift()).cumsum()).cumcount() + 1\n",
    "    #make streak negative if a losing streak\n",
    "    df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'] == 0]  = df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'] == 0]  * -1\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1f45b8-4a6f-484c-ae5e-fc7f77280ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_x_minus_league_avg(df, feature_list, team_feature):\n",
    "\n",
    "    # create a temp dataframe so that every date can be front-filled\n",
    "    # we need the current average for all 30 teams for every day during the season\n",
    "    # whether that team played or not. \n",
    "    # We will front-fill from previous days to ensure that every day has stats for every team\n",
    "    \n",
    "    \n",
    "    # create feature list for temp dataframe to hold league averages\n",
    "    temp_feature_list = feature_list.copy()\n",
    "    temp_feature_list.append(team_feature)\n",
    "    temp_feature_list.append(\"GAME_DATE_EST\")\n",
    "   \n",
    "    df_temp = df[temp_feature_list]\n",
    "\n",
    "    # populate the dataframe with all days played and forward fill previous value if a particular team did not play that day\n",
    "    # https://stackoverflow.com/questions/70362869\n",
    "    df_temp = (df_temp.set_index('GAME_DATE_EST')\n",
    "            .groupby([team_feature])[feature_list]\n",
    "            .apply(lambda x: x.asfreq('d', method = \"ffill\"))\n",
    "            .reset_index()\n",
    "            [temp_feature_list]\n",
    "            )\n",
    "    \n",
    "    # find the average across all teams for each day\n",
    "    df_temp = df_temp.groupby(['GAME_DATE_EST'])[feature_list].mean().reset_index()\n",
    "    \n",
    "    # rename features for merging\n",
    "    df_temp = df_temp.add_suffix('_LEAGUE_AVG')\n",
    "    temp_features = df_temp.columns\n",
    "    \n",
    "    # merge all-team averages with each record so that they can be subtracted\n",
    "    df = df.sort_values(by = 'GAME_DATE_EST', axis=0, ascending= True, ignore_index=True)   \n",
    "    df = pd.merge(df, df_temp, left_on='GAME_DATE_EST', right_on='GAME_DATE_EST_LEAGUE_AVG', how=\"left\",)\n",
    "    for feature in feature_list:\n",
    "        df[feature + \"_MINUS_LEAGUE_AVG\"] = df[feature] - df[feature + \"_LEAGUE_AVG\"]\n",
    "\n",
    "    # drop temp features that were only used for subtraction\n",
    "    df = df.drop(temp_features, axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3db72b8-c0a6-4b57-b315-58d51d5398fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_past_performance_all(df, roll_list):\n",
    "    \n",
    "    # roll_list = list of number of games for each rolling mean, e.g. [3, 5, 7, 10, 15]\n",
    "    \n",
    "    # new version 2022-11-03\n",
    "    # now ignoring season boundaries and with longer rolling means (20 and 40 games)\n",
    "    # AND create a field where the all-team average is subtracted from each field\n",
    "   \n",
    "    # add features showing how well each team has done in its last games\n",
    "    # regardless whether they were at home or away\n",
    "    # add rolling means for last 3, 5, 7, 10, 20, 40 games\n",
    "    # add win streaks (negative number if losing streak)\n",
    "    \n",
    "    #this data will need to be re-linked back to the main dataframe after all processing is done,\n",
    "    #joining TEAM1 to HOME_TEAM_ID for all records and then TEAM1 to VISITOR_TEAM_ID for all records\n",
    "    \n",
    "    #TEAM1 will be the key field. TEAM2 was used solely to process past team matchups\n",
    "\n",
    "\n",
    "    df = df.sort_values(by = ['TEAM1','GAME_DATE_EST'], axis=0, ascending=[True, True,], ignore_index=True)\n",
    "  \n",
    "    #streak of games won/lost, make negative is a losing streak\n",
    "    df['WIN_STREAK'] = df['TEAM1_win'].groupby((df['TEAM1_win'] != df.groupby(['TEAM1'])['TEAM1_win'].shift()).cumsum()).cumcount() + 1\n",
    "    df['WIN_STREAK'].loc[df['TEAM1_win'] == 0]  = df['WIN_STREAK'].loc[df['TEAM1_win'] == 0]  * -1\n",
    "    \n",
    "    #streak of games played at home/away, make negative if away streak\n",
    "    df['HOME_AWAY_STREAK'] = df['TEAM1_home'].groupby((df['TEAM1_home'] != df.groupby(['TEAM1'])['TEAM1_home'].shift()).cumsum()).cumcount() + 1\n",
    "    df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'] == 0]  = df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'] == 0]  * -1\n",
    "    \n",
    "    #rolling means \n",
    "    \n",
    "    feature_list = ['TEAM1_win', 'PTS', 'FG_PCT', 'FT_PCT', 'FG3_PCT', 'AST', 'REB']\n",
    "   \n",
    "    #create new feature names based upon rolling period\n",
    "    \n",
    "    roll_feature_list =[]\n",
    "\n",
    "    for feature in feature_list:\n",
    "        for roll in roll_list:\n",
    "            roll_feature_name = feature + '_AVG_LAST_' + str(roll) + '_ALL'\n",
    "            roll_feature_list.append(roll_feature_name)\n",
    "            df[roll_feature_name] = df.groupby(['TEAM1'])[feature].rolling(roll).mean().values\n",
    "\n",
    "    \n",
    "    \n",
    "    # determine league avg for each stat and then subtract it from the each team's average\n",
    "    # as a measure of how well that team compares to all teams in that moment in time\n",
    "    \n",
    "    #remove win averages from roll list - the league average will always be 0.5 (half the teams win, half lose)\n",
    "    roll_feature_list = [x for x in roll_feature_list if not x.startswith('TEAM1_win')]\n",
    "    \n",
    "    df = process_x_minus_league_avg(df, roll_feature_list, 'TEAM1')\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b992487-2cab-456e-89b6-4732e0292c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_new_features(df, df_consecutive):\n",
    "     \n",
    "    # add back all the new features created in the consecutive dataframe to the main dataframe\n",
    "    # all data for TEAM1 will be applied to the home team and then again to the visitor team\n",
    "    # except for head-to-head MATCHUP data, which will only be applied to home team (redundant to include for both)\n",
    "    # the letter '_x' will be appeneded to feature names when adding to home team\n",
    "    # the letter '_y' will be appended to feature names when adding to visitor team\n",
    "    # to match the existing convention in the dataset\n",
    "    \n",
    "    #first select out the new features\n",
    "    all_features = df_consecutive.columns.tolist()\n",
    "    link_features = ['GAME_ID', 'TEAM1', ]\n",
    "    redundant_features = ['GAME_DATE_EST','TEAM1_home','TEAM1_win','TEAM2','SEASON','PTS', 'FG_PCT', 'FT_PCT', 'FG3_PCT', 'AST', 'REB',]\n",
    "    matchup_features = [x for x in all_features if \"MATCHUP\" in x]\n",
    "    ignore_features = link_features + redundant_features\n",
    "    \n",
    "    new_features = [x for x in all_features if x not in ignore_features]\n",
    "    \n",
    "    # first home teams\n",
    "    \n",
    "    df1 = df_consecutive[df_consecutive['TEAM1_home'] == 1]\n",
    "    #add \"_x\" to new features\n",
    "    df1.columns = [x + '_x' if x in new_features else x for x in df1.columns]\n",
    "    #drop features that don't need to be merged\n",
    "    df1 = df1.drop(redundant_features,axis=1)\n",
    "    #change TEAM1 to HOME_TEAM_ID for easy merging\n",
    "    df1 = df1.rename(columns={'TEAM1': 'HOME_TEAM_ID'})\n",
    "    df = pd.merge(df, df1, how=\"left\", on=[\"GAME_ID\", \"HOME_TEAM_ID\"])\n",
    "    \n",
    "    #don't include matchup features for visitor team since they are equivant for both home and visitor\n",
    "    new_features = [x for x in new_features if x not in matchup_features]\n",
    "    df_consecutive = df_consecutive.drop(matchup_features,axis=1)\n",
    "    \n",
    "    # next visitor teams\n",
    "    \n",
    "    df2 = df_consecutive[df_consecutive['TEAM1_home'] == 0]\n",
    "    #add \"_y\" to new features\n",
    "    df2.columns = [x + '_y' if x in new_features else x for x in df2.columns]\n",
    "    #drop features that don't need to be merged\n",
    "    df2 = df2.drop(redundant_features,axis=1)\n",
    "    #change TEAM1 to VISITOR_TEAM_ID for easy merging\n",
    "    df2 = df2.rename(columns={'TEAM1': 'VISITOR_TEAM_ID'})\n",
    "    df = pd.merge(df, df2, how=\"left\", on=[\"GAME_ID\", \"VISITOR_TEAM_ID\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac89de67-9284-4b6b-897c-f27b747c73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_x_minus_y(df):\n",
    "    #Subtract visitor teams stats from the home teams stats for key fields\n",
    "    # field_x - field_y\n",
    "    \n",
    "    all_features = df.columns.tolist()\n",
    "    comparison_features = [x for x in all_features if \"_y\" in x]\n",
    "    \n",
    "    #don't include redunant features. (x - league_avg) - (y - league_avg) = x-y\n",
    "    comparison_features = [x for x in comparison_features if \"_MINUS_LEAGUE_AVG\" not in x]\n",
    "    \n",
    "    for feature in comparison_features:\n",
    "        feature_base = feature[:-2] #remove \"_y\" from the end\n",
    "        df[feature_base + \"_x_minus_y\"] = df[feature_base + \"_x\"] - df[feature_base + \"_y\"]\n",
    "        \n",
    "    #df = df.drop(\"CONFERENCE_x_minus_y\") #category variable not meaningful?\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763cc5a5-216b-490a-ada0-5c4f733aff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_rolling(df):\n",
    "    \n",
    "    drop_columns =[]\n",
    "    \n",
    "    all_columns = df.columns.tolist()\n",
    "    \n",
    "    drop_columns1 = ['HOME_TEAM_WINS','PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home']\n",
    "    drop_columns2 = ['PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away']\n",
    "    \n",
    "    drop_columns = drop_columns + drop_columns1\n",
    "    drop_columns = drop_columns + drop_columns2 \n",
    "    \n",
    "    use_columns = [item for item in all_columns if item not in drop_columns]\n",
    "    \n",
    "    return df[use_columns]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43bd7f16-7c11-438a-ac0c-9f4fd274fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_features(df):\n",
    "    \n",
    "    # lists for the number of games to including in rolling periods\n",
    "    #home_visitor_roll_list = [3, 5, 7, 10, 15]\n",
    "    #all_roll_list = [3, 5, 7, 10, 20, 40]\n",
    "    home_visitor_roll_list = [3, 15]\n",
    "    all_roll_list = [3, 20]\n",
    "        \n",
    "    df = remove_playoff_games(df)\n",
    "    df = fix_datatypes(df)\n",
    "    df = add_date_features(df)\n",
    "    df = add_rolling_home_visitor(df, \"HOME\", home_visitor_roll_list)\n",
    "    df = add_rolling_home_visitor(df, \"VISITOR\", home_visitor_roll_list)\n",
    "\n",
    "    #games must first be processed to sort all games in order per team\n",
    "    #regardless whether home or away\n",
    "    df_consecutive = process_games_consecutively(df)\n",
    "    df_consecutive = add_matchups(df_consecutive, home_visitor_roll_list)\n",
    "    df_consecutive = add_past_performance_all(df_consecutive, all_roll_list)\n",
    "\n",
    "    #add these features back to main dataframe\n",
    "    df = combine_new_features(df,df_consecutive)\n",
    "    \n",
    "    df = remove_non_rolling(df)\n",
    "    \n",
    "    df = process_x_minus_y(df)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d2db5-9767-40d5-bffe-714a84ecfd14",
   "metadata": {},
   "source": [
    "### Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "577e56a2-8224-4cc8-bfc1-89df0dcf6fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\4094627603.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  = df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\4094627603.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  = df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\1489873892.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'] == 0]  = df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\154489856.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['WIN_STREAK'].loc[df['TEAM1_win'] == 0]  = df['WIN_STREAK'].loc[df['TEAM1_win'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\154489856.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'] == 0]  = df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\4094627603.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  = df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\4094627603.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  = df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\1489873892.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'] == 0]  = df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\154489856.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['WIN_STREAK'].loc[df['TEAM1_win'] == 0]  = df['WIN_STREAK'].loc[df['TEAM1_win'] == 0]  * -1\n",
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_6640\\154489856.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'] == 0]  = df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'] == 0]  * -1\n"
     ]
    }
   ],
   "source": [
    "train_features = add_all_features(train)\n",
    "test_features = add_all_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc1b53-e961-4415-bbc2-4cd0f9c427ba",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada7682b-d7be-4786-b35c-0ea7b20b8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 2nd to last season from test set\n",
    "#it was needed to just generate rolling mean that began in previous season\n",
    "\n",
    "latest_season = test_features['SEASON'].unique().max()\n",
    "test_features = test_features[test_features['SEASON'] >= (latest_season)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2ba3858-eddd-48d5-ba00-3e4aa8ce64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv(DATAPATH / \"train_features.csv\",index=False)\n",
    "test_features.to_csv(DATAPATH / \"test_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68706fa-8e4d-406e-aab4-b24f0f868366",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bceeb1ef-315d-4994-9f09-42fdf36e95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation bar chart\n",
    "  \n",
    "drop_cols = ['GAME_ID']\n",
    "n = 30\n",
    "\n",
    "#plot_corr_barchart(train_features,drop_cols,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e7af14a-1255-43a9-8fd1-b9e48b3d7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations vs target\n",
    "\n",
    "target = 'TARGET'\n",
    "n = 30\n",
    "drop_cols = ['GAME_ID','TARGET']\n",
    "\n",
    "#plot_corr_vs_target(train_features, target, drop_cols, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "166b0bc3-841b-44f3-a310-dc0be3b0cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sweetviz report\n",
    "\n",
    "#run_sweetviz_report(train_features,'TARGET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412b1c5-6116-40d4-be72-5c2962ffc4a5",
   "metadata": {},
   "source": [
    "### Changelog / Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b1b97-2e4a-4ea8-a73d-23fc46973074",
   "metadata": {},
   "source": [
    "**2022-10-30**\n",
    "\n",
    "Added \"_by_season\" to old versions of following functions and made new versions of each.\n",
    "\n",
    " - add_matchups\n",
    " - add_past_performance_home_away\n",
    " - add_past_performance_all\n",
    " \n",
    " New versions:\n",
    " \n",
    " - no longer grouped by season (rolling averages can extend back to previous season)\n",
    " - added longer term rolling/expanding averages\n",
    " \n",
    " **2022-10-31**\n",
    " \n",
    " Added function to subtract visitor team stats from home team stats - process_differences()\n",
    "\n",
    " **2022-11-03**\n",
    " \n",
    " - added code to subtract league avg from stats\n",
    " - added function to remove playoff games\n",
    " \n",
    " **2022-11-04 thru 06**\n",
    " \n",
    " - extensive refactoring of code, including using lists as parameters and increasing code re-usability with sub-functions and parameter lists\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54a32f-68f7-4bc0-a896-b743af6bb0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba",
   "language": "python",
   "name": "nba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
